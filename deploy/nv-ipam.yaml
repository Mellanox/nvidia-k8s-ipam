---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nv-ipam-node
rules:
  - apiGroups:
      - ""
    resources:
      - nodes
      - pods
    verbs:
      - get
      - list
      - watch
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nv-ipam-node
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nv-ipam-node
subjects:
  - kind: ServiceAccount
    name: nv-ipam-node
    namespace: kube-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nv-ipam-node
  namespace: kube-system
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nv-ipam-node-ds
  namespace: kube-system
  labels:
    tier: node
    app: nv-ipam-node
    name: nv-ipam-node
spec:
  selector:
    matchLabels:
      name: nv-ipam-node
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        tier: node
        app: nv-ipam-node
        name: nv-ipam-node
    spec:
      tolerations:
        - operator: Exists
          effect: NoSchedule
        - operator: Exists
          effect: NoExecute
      serviceAccountName: nv-ipam-node
      containers:
        - name: nv-ipam-node
          image: ghcr.io/mellanox/nvidia-k8s-ipam:latest
          imagePullPolicy: IfNotPresent
          env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          command: [ "/ipam-node" ]
          args:
            - --node-name=$(NODE_NAME)
            - --v=1 # log level for ipam-node
            - --logging-format=json
            - --bind-address=unix:///var/lib/cni/nv-ipam/daemon.sock
            - --store-file=/var/lib/cni/nv-ipam/store
            - --cni-daemon-socket=unix:///var/lib/cni/nv-ipam/daemon.sock
            - --cni-daemon-call-timeout=5 # 5 seconds
            - --cni-bin-dir=/opt/cni/bin
            - --cni-conf-dir=/etc/cni/net.d/nv-ipam.d
            - --cni-log-file=/var/log/nv-ipam-cni.log
            - --cni-log-level=info # log level for shim CNI
          resources:
            requests:
              cpu: "100m"
              memory: "50Mi"
            limits:
              cpu: "300m"
              memory: "300Mi"
          volumeMounts:
            - name: cnibin
              mountPath: /opt/cni/bin
            - name: cniconf
              mountPath: /etc/cni/net.d/nv-ipam.d
            - name: daemonstate
              mountPath: /var/lib/cni/nv-ipam/
      terminationGracePeriodSeconds: 10
      volumes:
        - name: cnibin
          hostPath:
            path: /opt/cni/bin
            type: DirectoryOrCreate
        - name: cniconf
          hostPath:
            path: /etc/cni/net.d/nv-ipam.d
            type: DirectoryOrCreate
        - name: daemonstate
          hostPath:
            path: /var/lib/cni/nv-ipam/
            type: DirectoryOrCreate
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nv-ipam-controller
rules:
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - get
      - list
      - patch
      - update
      - watch
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - coordination.k8s.io
    resources:
      - leases
    verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nv-ipam-controller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nv-ipam-controller
subjects:
  - kind: ServiceAccount
    name: nv-ipam-controller
    namespace: kube-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nv-ipam-controller
  namespace: kube-system
---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: nv-ipam-controller
  namespace: kube-system
  annotations:
    kubernetes.io/description: |
      This deployment launches the nv-ipam controller for nv-ipam.
spec:
  strategy:
    type: RollingUpdate
  replicas: 1
  selector:
    matchLabels:
      name: nv-ipam-controller
  template:
    metadata:
      labels:
        name: nv-ipam-controller
    spec:
      priorityClassName: system-cluster-critical
      serviceAccountName: nv-ipam-controller
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: name
                      operator: In
                      values:
                        - nv-ipam-controller
                topologyKey: "kubernetes.io/hostname"
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              preference:
                matchExpressions:
                  - key: node-role.kubernetes.io/master
                    operator: In
                    values:
                      - ""
            - weight: 1
              preference:
                matchExpressions:
                  - key: node-role.kubernetes.io/control-plane
                    operator: In
                    values:
                      - ""
      tolerations:
        - key: node-role.kubernetes.io/master
          operator: Exists
          effect: NoSchedule
        - key: node-role.kubernetes.io/control-plane
          operator: Exists
          effect: NoSchedule
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      containers:
        - name: nv-ipam-controller
          image: ghcr.io/mellanox/nvidia-k8s-ipam:latest
          imagePullPolicy: IfNotPresent
          command: [ "/ipam-controller" ]
          args:
            - --config-name=nvidia-k8s-ipam-config
            - --config-namespace=$(POD_NAMESPACE)
            - --leader-elect=true
            - --leader-elect-namespace=$(POD_NAMESPACE)
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - "ALL"
          livenessProbe:
            httpGet:
              path: /healthz
              port: 8081
            initialDelaySeconds: 15
            periodSeconds: 20
          readinessProbe:
            httpGet:
              path: /readyz
              port: 8081
            initialDelaySeconds: 5
            periodSeconds: 10
          resources:
            requests:
              cpu: 100m
              memory: 300Mi
